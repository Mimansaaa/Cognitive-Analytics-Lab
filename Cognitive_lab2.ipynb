{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBL1D7IPJinCndwrHGUqYJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","class CustomNeuralNetwork:\n","    def __init__(self, input_size, hidden_layer_sizes, output_size, custom_weights=None):\n","        self.input_size = input_size\n","        self.hidden_layer_sizes = hidden_layer_sizes\n","        self.output_size = output_size\n","\n","        if custom_weights is not None:\n","            # Use custom weights if provided\n","            self.hidden_weights = custom_weights['hidden_weights']\n","            self.output_weights = custom_weights['output_weights']\n","        else:\n","            # Generate random weights if custom weights are not provided\n","            self.hidden_weights = [np.random.rand(hidden_size, input_size) for hidden_size in hidden_layer_sizes]\n","            self.output_weights = np.random.rand(output_size, hidden_layer_sizes[-1])\n","\n","        # Activation functions for each layer\n","        self.activation_functions = [self.sigmoid for _ in range(len(hidden_layer_sizes) + 1)]\n","\n","## All the ACtivation functions are defined here\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    def relu(self, x):\n","        return np.maximum(0, x)\n","\n","    def tanh(self, x):\n","        return np.tanh(x)\n","\n","    def softmax(self, x):\n","        exp_values = np.exp(x - np.max(x))\n","        return exp_values / np.sum(exp_values, axis=0)\n","\n","    def feedforward(self, input_data):\n","        # Arrange input_data in column-vector format\n","        input_layer = input_data.reshape((self.input_size, 1))\n","\n","        # Calculation for Hidden_layers\n","        hidden_layer_outputs = []\n","        for i, layer_weights in enumerate(self.hidden_weights):\n","            hidden_layer_input = np.dot(layer_weights, input_layer)\n","            hidden_layer_output = self.activation_functions[i](hidden_layer_input)\n","            hidden_layer_outputs.append(hidden_layer_output)\n","            input_layer = hidden_layer_output\n","\n","        # Calculation for Output_layer\n","        output_layer_input = np.dot(self.output_weights, hidden_layer_outputs[-1])\n","        output_layer_output = self.activation_functions[-1](output_layer_input)\n","\n","        return output_layer_output\n","\n","# User input for customization of NN\n","input_size = int(input(\"Enter the number of inputs in the input layer: \"))\n","hidden_layer_count = int(input(\"Enter the number of hidden layers: \"))\n","hidden_layer_sizes = [int(input(f\"Enter the number of neurons in hidden layer {i + 1}: \")) for i in range(hidden_layer_count)]\n","output_size = int(input(\"Enter the number of outputs in the output layer: \"))\n","\n","# User input for activation functions\n","activation_choices = {\n","    1: \"Sigmoid\",\n","    2: \"ReLU\",\n","    3: \"Tanh\",\n","    4: \"Softmax\"\n","}\n","\n","activation_functions = []\n","for i in range(hidden_layer_count + 1):\n","    print(f\"Select activation function for layer {i + 1}:\")\n","    for choice, function_name in activation_choices.items():\n","        print(f\"{choice}. {function_name}\")\n","\n","    user_choice = int(input(\"Enter your choice: \"))\n","    if user_choice == 1:\n","        activation_functions.append(\"sigmoid\")\n","    elif user_choice == 2:\n","        activation_functions.append(\"relu\")\n","    elif user_choice == 3:\n","        activation_functions.append(\"tanh\")\n","    elif user_choice == 4:\n","        activation_functions.append(\"softmax\")\n","    else:\n","        print(\"Invalid choice. Using sigmoid as default.\")\n","        activation_functions.append(\"sigmoid\")\n","\n","# User input for custom weights\n","custom_weights_choice = input(\"Do you want to input custom weights? (yes/no): \").lower()\n","if custom_weights_choice == 'yes':\n","    custom_hidden_weights = [np.array(eval(input(f\"Enter custom weights for hidden layer {i + 1}: \"))) for i in range(hidden_layer_count)]\n","    custom_output_weights = np.array(eval(input(\"Enter custom weights for output layer: \")))\n","    custom_weights = {'hidden_weights': custom_hidden_weights, 'output_weights': custom_output_weights}\n","else:\n","    custom_weights = None\n","\n","# Initialization of the CustomNeuralNetwork\n","neural_network = CustomNeuralNetwork(input_size, hidden_layer_sizes, output_size, custom_weights)\n","neural_network.activation_functions = [getattr(neural_network, func) for func in activation_functions]\n","\n","# Input data by the user\n","input_data = np.array([float(input(f\"Enter input {i + 1}: \")) for i in range(input_size)])\n","\n","# Calculation of the output\n","output_result = neural_network.feedforward(input_data)\n","\n","# Display\n","print(\"Input Data:\\n\", input_data)\n","print(\"Output Result:\\n\", output_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FAuIEL3GwB1I","executionInfo":{"status":"ok","timestamp":1706071546657,"user_tz":-330,"elapsed":33512,"user":{"displayName":"Mimansa Pathania","userId":"11433804632114621765"}},"outputId":"cc51ab3a-f7b2-48a0-badb-156d92e3d257"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the number of inputs in the input layer: 2\n","Enter the number of hidden layers: 1\n","Enter the number of neurons in hidden layer 1: 3\n","Enter the number of outputs in the output layer: 2\n","Select activation function for layer 1:\n","1. Sigmoid\n","2. ReLU\n","3. Tanh\n","4. Softmax\n","Enter your choice: 2\n","Select activation function for layer 2:\n","1. Sigmoid\n","2. ReLU\n","3. Tanh\n","4. Softmax\n","Enter your choice: 3\n","Do you want to input custom weights? (yes/no): no\n","Enter input 1: 0.6\n","Enter input 2: 0.8\n","Input Data:\n"," [0.6 0.8]\n","Output Result:\n"," [[0.45984532]\n"," [0.83388909]]\n"]}]}]}